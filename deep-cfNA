#!/usr/bin/env python

import argparse
import os
import pkg_resources
from deep_cfNA import deep_cfNA_training
from deep_cfNA.deep_cfNA_model import save_model, load_model
from deep_cfNA.deep_cfNA_training import training_sample, validation_sample
from deep_cfNA.bed_utils import prediction_generator
from sequencing_tools.io_tools import xopen
from multiprocessing import Pool, cpu_count
from functools import partial
import sys

def getopt():
    parser = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]))
    subparsers = parser.add_subparsers(help='Run type for deep cfNA',
                                    dest='subcommand')
    subparsers.required = True

    #add training commands
    training = subparsers.add_parser('train',help='deep_cfNA training')
    training.add_argument('--train_bed', help='BED file for fragments:  \n'\
                        'For each record in BED file, extract the sequence, and center it \n'\
                        'fill up both sides to length of (seq_length) with Ns.\n' \
                        'Bed files need these columns: \n'\
                        '1. chrom \n'\
                        '2. start\n'\
                        '3. end\n'\
                        '4.\n'\
                        '5. \n'\
                        '6. strand\n'\
                        '7. label: (DNA or RNA)',
                        required=True)
    training.add_argument('--validation_bed', help ='bed file for validation')
    training.add_argument('--epoch', default=10, type=int)
    training.add_argument('--genome', help ='genome fasta file (must have faidx)', required=True)
    training.add_argument('--model_prefix', help ='where to save the model')


    #add validation command
    validation = subparsers.add_parser('validation', help='deep_cfNA validation')
    validation.add_argument('--genome', help ='genome fasta file (must have faidx)', required=True)
    validation.add_argument('--validation_bed', help ='bed file for validation', required=True)
    validation.add_argument('--model_prefix', help ='where to save the model', required=True)


    #add_test commands
    prediction = subparsers.add_parser('predict', help = 'deep cfNA prediction using existing model')
    prediction.add_argument('--inbed',help='BED file for fragments:  \n'\
                        'For each record in BED file, extract the sequence, and center it \n'\
                        'fill up both sides to length of (seq_length) with Ns.\n' \
                        'Bed files need these columns: \n'\
                        '1. chrom \n'\
                        '2. start\n'\
                        '3. end\n'\
                        '4.\n'\
                        '5. \n'\
                        '6. strand\n'\
                        '7. label: (DNA or RNA)',
                        required=True)
    prediction.add_argument('--genome', help ='genome fasta file (must have faidx)', required=True)
    prediction.add_argument('--out', help ='out BED file (default: - )', default = '-')
    prediction.add_argument('--batch_size', help ='batch size for prediction', default = 1000, type=int)
    default_model_predix = pkg_resources.resource_filename('deep_cfNA', 'model')
    default_model_predix = os.path.dirname(os.path.dirname(default_model_predix)) + "/model/deep_cfNA"
    prediction.add_argument('--model_prefix', default=default_model_predix)

    return parser.parse_args()


def validation(args, model):
    '''
    validation using a known bed file
    '''
        feature_generator = prediction_generator(args.validation_bed, args.genome, 
                                                batch_size = args.batch_size)
    validation_sample(args.validation_bed, args.genome, model)


def training(args):
    '''
    training model with ground truth bed
    '''
    history, model = training_sample(args.train_bed, args.genome, args.epoch)

    if args.model_prefix:
        save_model(model, prefix = args.model_prefix)

    if args.validation_bed:
        validation(args, model)


def predict_job(model_prefix, arg):
    '''
    Actual work for predicting in batch
    '''
    features, bed_lines = arg
    model = load_model(model_prefix, message=False)
    predictions = model.predict_classes(features)
    out_lines = ''
    for prediction, bed_line in zip(predictions, bed_lines):
        label = 'DNA' if prediction == 1 else 'RNA'
        out_line = bed_line + '\t' + label + '\n'
        out_lines += out_line
    return out_lines


def prediction(args, model_prefix):
    '''
    Run prediction, needs a loaded keras model, genome and bed file
    '''
    feature_generator = prediction_generator(args.inbed, args.genome, batch_size = args.batch_size)

    #define output
    if args.out == '-' or args.out == "/dev/stdout":
        out = sys.stdout  
        stdout = True
    else: 
        out = xopen(args.out, 'w')
        stdout = False

    predict_func = partial(predict_job, model_prefix)
    p = Pool(cpu_count())
    jobs = p.imap(predict_func, feature_generator, chunksize = 10)
    for batch, out_lines in enumerate(jobs):
        print(out_lines, file = out)
        if batch % 100 == 0:
            print('Processed %i batches' %(batch + 1), file = sys.stderr)
    if not stdout:
        out.close()


def main():
    args = getopt()

    if args.subcommand == 'train':
        training(args)

    else:
        if args.subcommand == 'validation':
            model = load_model(args.model_prefix)
            validation(args, model)

        elif args.subcommand == 'predict':
            prediction(args, args.model_prefix)
           
if __name__ == '__main__':
    main()
