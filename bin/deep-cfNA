#!/usr/bin/env python

import argparse
import os
import pkg_resources
from deep_cfNA import deep_cfNA_training
from deep_cfNA.model import Deep_cfNA
from deep_cfNA.train import training_sample, validation_sample
from deep_cfNA.bed_utils import prediction_generator
from sequencing_tools.io_tools import xopen
from multiprocessing import Pool, cpu_count
from functools import partial
import sys
N_padded = True

def getopt():
    parser = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]))
    subparsers = parser.add_subparsers(help='Run type for deep cfNA',
                                    dest='subcommand')
    subparsers.required = True

    #add training subcommands
    training = subparsers.add_parser('train',help='deep_cfNA training')
    training.add_argument('--train_bed_positive', help='BED file prefix for fragments, for positive label:  \n'\
                        'For each record in BED file, extract the sequence, and center it \n'\
                        'fill up both sides to length of (seq_length) with Ns.\n' \
                        'Bed files need these columns: \n'\
                        '1. chrom \n'\
                        '2. start\n'\
                        '3. end\n'\
                        '4.\n'\
                        '5. \n'\
                        '6. strand\n'\
                        '7. label: (DNA or RNA)',
                        required=True)
    training.add_argument('--train_bed_negative', help='BED file prefix for fragments, for negative label \n',
                          required=True)
    training.add_argument('--validation_bed', help ='bed file for validation')
    training.add_argument('--epochs', default=10, type=int, help = 'How many epochs?')
    training.add_argument('--steps', default=10000, type=int, help = 'How many steps per epoch (500 samples/step)')
    training.add_argument('-g','--genome', help ='genome fasta file (must have faidx)', required=True)
    training.add_argument('-p','--model_prefix', help ='where to save the model')
    training.add_argument('--update', 
                          help ='Supply with model prefix to keep training the same model', 
                          action='store_true')
    training.add_argument('--reduced_model', help = 'Using a reduced model', 
                          action='store_true')


    #add validation subcommand
    validation = subparsers.add_parser('validate', help='deep_cfNA validation')
    validation.add_argument('--genome', help ='genome fasta file (must have faidx)', required=True)
    validation.add_argument('--validation_bed', help ='bed file for validation', required=True)
    validation.add_argument('--model_prefix', help ='where to save the model', required=True)
    validation.add_argument('--reduced_model', help = 'Using a reduced model', 
                          action='store_true')


    #add_test subcommands
    prediction = subparsers.add_parser('predict', help = 'deep cfNA prediction using existing model')
    prediction.add_argument('-i','--inbed',help='BED file for fragments:  \n'\
                        'For each record in BED file, extract the sequence, and center it \n'\
                        'fill up both sides to length of (seq_length) with Ns.\n' \
                        'Bed files need these columns: \n'\
                        '1. chrom \n'\
                        '2. start\n'\
                        '3. end\n'\
                        '4.\n'\
                        '5. \n'\
                        '6. strand\n'\
                        '7. label: (DNA or RNA)',
                        required=True)
    prediction.add_argument('-g','--genome', help ='genome fasta file (must have faidx)', required=True)
    prediction.add_argument('-o','--out', help ='out BED file (default: - )', default = '-')
    default_model_predix = pkg_resources.resource_filename('deep_cfNA', 'model')
    default_model_predix = os.path.dirname(os.path.dirname(default_model_predix)) + "/model/deep_cfNA"
    prediction.add_argument('-p','--model_prefix', default=default_model_predix)
    prediction.add_argument('--reduced_model', help = 'Using a reduced model', 
                          action='store_true')

    return parser.parse_args()


def validation(args, model):
    '''
    validation using a known bed file
    '''
    feature_generator = prediction_generator(args.validation_bed, args.genome, 
                                                batch_size = 1000,
                                             N_padded = N_padded)
    validation_sample(args.validation_bed, args.genome, model)


def training(args):
    '''
    training model with ground truth bed
    '''

    model = Deep_cfNA(reduced_model = True) if args.reduced_model else Deep_cfNA()
    if args.update:
        try:
            model.load_model(args.model_prefix)
            print('Updating %s' %args.model_prefix)
        except FileNotFoundError:
            sys.exit('Model not found: %s' %(args.model_prefix))
    model.compile()
    history, model = training_sample(args.train_bed_positive,
                                     args.train_bed_negative, 
                                     args.genome, 
                                     steps = args.steps,
                                     epochs = args.epochs, 
                                     model = model,
                                     N_padded = N_padded,
                                     validation_bed = args.validation_bed)

    if args.model_prefix:
        model.save_model(prefix = args.model_prefix)

    if args.validation_bed:
        validation(args, model)


def predict_job(model_prefix, reduced_model, arg):
    '''
    Actual work for predicting in batch
    '''
    features, bed_lines = arg
    model = Deep_cfNA(reduced_model = True) if reduced_model else Deep_cfNA()
    model.load_model(model_prefix, message=False)
    predictions = model.predict_classes(features)
    out_lines = ''
    for prediction, bed_line in zip(predictions, bed_lines):
        label = 'DNA' if prediction == 1 else 'RNA'
        out_line = bed_line + '\t' + label + '\n'
        out_lines += out_line
    return out_lines


def prediction(args, model_prefix):
    '''
    Run prediction, needs a loaded keras model, genome and bed file
    '''
    feature_generator = prediction_generator(args.inbed, args.genome, batch_size = 1000, N_padded = N_padded)

    #define output
    if args.out == '-' or args.out == "/dev/stdout":
        out = sys.stdout  
        stdout = True
    else: 
        out = xopen(args.out, 'w')
        stdout = False

    predict_func = partial(predict_job, model_prefix, args.reduced_model)
    p = Pool(cpu_count())
    jobs = p.imap_unordered(predict_func, feature_generator, chunksize = 10)
    p.close()
    p.join()
    for batch, out_lines in enumerate(jobs):
        out.write(out_lines)
        if batch % 100 == 0:
            print('Processed %i batches' %(batch + 1), file = sys.stderr)
    if not stdout:
        out.close()


def main():
    args = getopt()

    if args.subcommand == 'train':
        training(args)

    else:
        if args.subcommand == 'validate':
            model = Deep_cfNA(reduced_model = True) if args.reduced_model else Deep_cfNA()
            model.load_model(args.model_prefix)
            validation(args, model)

        elif args.subcommand == 'predict':
            prediction(args, args.model_prefix)
           
if __name__ == '__main__':
    main()
